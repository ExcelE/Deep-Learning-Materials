{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing with Tensorboard\n",
    "\n",
    "The most popular use of Tensorboard is to manage multiple models. When training there are a lot of fine tuning to do that it gets tedious. Some parameters like the structure of the neural network, the optimizer used, the learning rate in the optimizer, etc. permutates to thousands to millions of possible models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The things we are going to tweak in:\n",
    "\n",
    "```model.add(Conv2D(64, (3,3), input_shape(X.shape[1:]))```\n",
    "\n",
    "are the kernel size ```(3,3)```, number of layers, number of nodes per layer ```64```, and the choice of having a dense layer at the end."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dense_layers = [0, 1, 2]\n",
    "layer_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are permutating to all the possibilities based on the options above."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see it come together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"pickles/X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"pickles/y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layers = [0, 1, 2]\n",
    "layer_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 8s 445us/step - loss: 0.6288 - acc: 0.6492 - val_loss: 0.5843 - val_acc: 0.7071\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 7s 376us/step - loss: 0.5360 - acc: 0.7347 - val_loss: 0.5454 - val_acc: 0.7321\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 7s 373us/step - loss: 0.4999 - acc: 0.7582 - val_loss: 0.5478 - val_acc: 0.7263\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 7s 375us/step - loss: 0.4671 - acc: 0.7849 - val_loss: 0.5315 - val_acc: 0.7417\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 7s 381us/step - loss: 0.4451 - acc: 0.7933 - val_loss: 0.5707 - val_acc: 0.7147\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 6s 369us/step - loss: 0.4259 - acc: 0.8041 - val_loss: 0.5573 - val_acc: 0.7346\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 6s 364us/step - loss: 0.4094 - acc: 0.8146 - val_loss: 0.5740 - val_acc: 0.7197\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 7s 375us/step - loss: 0.3895 - acc: 0.8285 - val_loss: 0.5409 - val_acc: 0.7473\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 7s 373us/step - loss: 0.3759 - acc: 0.8340 - val_loss: 0.5922 - val_acc: 0.7159\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 7s 382us/step - loss: 0.3648 - acc: 0.8394 - val_loss: 0.5534 - val_acc: 0.7406\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 7s 416us/step - loss: 0.6300 - acc: 0.6429 - val_loss: 0.5863 - val_acc: 0.6924\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 7s 393us/step - loss: 0.5368 - acc: 0.7345 - val_loss: 0.5283 - val_acc: 0.7456\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 7s 399us/step - loss: 0.4901 - acc: 0.7671 - val_loss: 0.5029 - val_acc: 0.7573\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 7s 424us/step - loss: 0.4659 - acc: 0.7805 - val_loss: 0.4861 - val_acc: 0.7628\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 7s 392us/step - loss: 0.4400 - acc: 0.7952 - val_loss: 0.4714 - val_acc: 0.7814\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 7s 393us/step - loss: 0.4150 - acc: 0.8112 - val_loss: 0.5126 - val_acc: 0.7573\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 7s 391us/step - loss: 0.3971 - acc: 0.8204 - val_loss: 0.4748 - val_acc: 0.7801\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 7s 394us/step - loss: 0.3767 - acc: 0.8330 - val_loss: 0.4643 - val_acc: 0.7921\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 7s 390us/step - loss: 0.3581 - acc: 0.8433 - val_loss: 0.4547 - val_acc: 0.7910\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 8s 433us/step - loss: 0.3397 - acc: 0.8527 - val_loss: 0.4582 - val_acc: 0.7949\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 7s 425us/step - loss: 0.6411 - acc: 0.6215 - val_loss: 0.5858 - val_acc: 0.6913\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 7s 409us/step - loss: 0.5401 - acc: 0.7296 - val_loss: 0.5083 - val_acc: 0.7523\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 7s 415us/step - loss: 0.4879 - acc: 0.7656 - val_loss: 0.4853 - val_acc: 0.7734\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 7s 412us/step - loss: 0.4582 - acc: 0.7862 - val_loss: 0.4698 - val_acc: 0.7819\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 7s 408us/step - loss: 0.4364 - acc: 0.7981 - val_loss: 0.4424 - val_acc: 0.7996\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 7s 408us/step - loss: 0.4128 - acc: 0.8087 - val_loss: 0.4408 - val_acc: 0.7950\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 7s 411us/step - loss: 0.3943 - acc: 0.8202 - val_loss: 0.4110 - val_acc: 0.8125\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 7s 419us/step - loss: 0.3733 - acc: 0.8330 - val_loss: 0.4158 - val_acc: 0.8117\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 7s 427us/step - loss: 0.3575 - acc: 0.8417 - val_loss: 0.4105 - val_acc: 0.8116\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 7s 425us/step - loss: 0.3425 - acc: 0.8494 - val_loss: 0.3805 - val_acc: 0.8279\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 8s 454us/step - loss: 0.6160 - acc: 0.6673 - val_loss: 0.5669 - val_acc: 0.7177\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 8s 436us/step - loss: 0.5253 - acc: 0.7454 - val_loss: 0.5434 - val_acc: 0.7349\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 8s 445us/step - loss: 0.4875 - acc: 0.7707 - val_loss: 0.5723 - val_acc: 0.7161\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 8s 438us/step - loss: 0.4533 - acc: 0.7907 - val_loss: 0.5514 - val_acc: 0.7231\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 8s 440us/step - loss: 0.4247 - acc: 0.8037 - val_loss: 0.5425 - val_acc: 0.7352\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 8s 439us/step - loss: 0.3984 - acc: 0.8238 - val_loss: 0.5412 - val_acc: 0.7392\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 8s 441us/step - loss: 0.3792 - acc: 0.8303 - val_loss: 0.5481 - val_acc: 0.7402\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 8s 440us/step - loss: 0.3546 - acc: 0.8443 - val_loss: 0.5563 - val_acc: 0.7427\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 8s 440us/step - loss: 0.3334 - acc: 0.8566 - val_loss: 0.5629 - val_acc: 0.7435\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 8s 440us/step - loss: 0.3111 - acc: 0.8708 - val_loss: 0.5842 - val_acc: 0.7377\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 9s 514us/step - loss: 0.6130 - acc: 0.6581 - val_loss: 0.5457 - val_acc: 0.7280\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 9s 493us/step - loss: 0.5113 - acc: 0.7521 - val_loss: 0.5005 - val_acc: 0.7553\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 9s 492us/step - loss: 0.4650 - acc: 0.7792 - val_loss: 0.4743 - val_acc: 0.7786\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 9s 497us/step - loss: 0.4394 - acc: 0.7984 - val_loss: 0.4639 - val_acc: 0.7896\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 9s 495us/step - loss: 0.4186 - acc: 0.8091 - val_loss: 0.4643 - val_acc: 0.7821\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 9s 490us/step - loss: 0.3945 - acc: 0.8269 - val_loss: 0.4519 - val_acc: 0.7898\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 9s 494us/step - loss: 0.3743 - acc: 0.8337 - val_loss: 0.4551 - val_acc: 0.7913\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 9s 490us/step - loss: 0.3517 - acc: 0.8478 - val_loss: 0.4516 - val_acc: 0.7908\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 9s 489us/step - loss: 0.3326 - acc: 0.8556 - val_loss: 0.4564 - val_acc: 0.7961\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 9s 489us/step - loss: 0.3135 - acc: 0.8648 - val_loss: 0.4577 - val_acc: 0.7956\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 10s 554us/step - loss: 0.6435 - acc: 0.6189 - val_loss: 0.6022 - val_acc: 0.6796\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 9s 529us/step - loss: 0.5298 - acc: 0.7361 - val_loss: 0.5123 - val_acc: 0.7508\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 9s 524us/step - loss: 0.4656 - acc: 0.7796 - val_loss: 0.4894 - val_acc: 0.7636\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 9s 518us/step - loss: 0.4252 - acc: 0.8031 - val_loss: 0.4295 - val_acc: 0.8075\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 9s 525us/step - loss: 0.3902 - acc: 0.8257 - val_loss: 0.4328 - val_acc: 0.7976\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 9s 508us/step - loss: 0.3657 - acc: 0.8368 - val_loss: 0.4104 - val_acc: 0.8185\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 9s 507us/step - loss: 0.3360 - acc: 0.8539 - val_loss: 0.4248 - val_acc: 0.8041\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17462/17462 [==============================] - 9s 517us/step - loss: 0.3085 - acc: 0.8654 - val_loss: 0.3900 - val_acc: 0.8351\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 9s 506us/step - loss: 0.2850 - acc: 0.8786 - val_loss: 0.3936 - val_acc: 0.8298\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 9s 516us/step - loss: 0.2654 - acc: 0.8860 - val_loss: 0.4133 - val_acc: 0.8196\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 11s 634us/step - loss: 0.6217 - acc: 0.6557 - val_loss: 0.5829 - val_acc: 0.6933\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 10s 590us/step - loss: 0.5321 - acc: 0.7409 - val_loss: 0.5540 - val_acc: 0.7229\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 10s 574us/step - loss: 0.4857 - acc: 0.7685 - val_loss: 0.5597 - val_acc: 0.7167\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 10s 584us/step - loss: 0.4525 - acc: 0.7886 - val_loss: 0.5619 - val_acc: 0.7289\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 10s 583us/step - loss: 0.4140 - acc: 0.8131 - val_loss: 0.5443 - val_acc: 0.7428\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 12s 693us/step - loss: 0.3878 - acc: 0.8252 - val_loss: 0.5486 - val_acc: 0.7396\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 10s 589us/step - loss: 0.3547 - acc: 0.8439 - val_loss: 0.5815 - val_acc: 0.7341\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 10s 588us/step - loss: 0.3203 - acc: 0.8660 - val_loss: 0.5981 - val_acc: 0.7241\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 10s 579us/step - loss: 0.2881 - acc: 0.8816 - val_loss: 0.6109 - val_acc: 0.7282\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 11s 602us/step - loss: 0.2571 - acc: 0.8984 - val_loss: 0.6204 - val_acc: 0.7366\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 13s 736us/step - loss: 0.6463 - acc: 0.6242 - val_loss: 0.5939 - val_acc: 0.6937\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 12s 696us/step - loss: 0.5436 - acc: 0.7278 - val_loss: 0.5263 - val_acc: 0.7397\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 13s 719us/step - loss: 0.4847 - acc: 0.7689 - val_loss: 0.5016 - val_acc: 0.7575\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 12s 712us/step - loss: 0.4540 - acc: 0.7874 - val_loss: 0.4722 - val_acc: 0.7741\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 12s 700us/step - loss: 0.4251 - acc: 0.8052 - val_loss: 0.5302 - val_acc: 0.7531\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 12s 689us/step - loss: 0.3991 - acc: 0.8199 - val_loss: 0.4495 - val_acc: 0.7925\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 12s 697us/step - loss: 0.3781 - acc: 0.8307 - val_loss: 0.4413 - val_acc: 0.7960\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 12s 695us/step - loss: 0.3548 - acc: 0.8412 - val_loss: 0.4543 - val_acc: 0.7904\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 12s 694us/step - loss: 0.3294 - acc: 0.8574 - val_loss: 0.4364 - val_acc: 0.8055\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 14s 785us/step - loss: 0.3066 - acc: 0.8670 - val_loss: 0.4993 - val_acc: 0.7855\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 13s 746us/step - loss: 0.6315 - acc: 0.6318 - val_loss: 0.5633 - val_acc: 0.7151\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 13s 734us/step - loss: 0.5184 - acc: 0.7435 - val_loss: 0.4821 - val_acc: 0.7710\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 13s 734us/step - loss: 0.4518 - acc: 0.7883 - val_loss: 0.4547 - val_acc: 0.7865\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 13s 716us/step - loss: 0.4095 - acc: 0.8144 - val_loss: 0.4317 - val_acc: 0.8052\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 13s 754us/step - loss: 0.3730 - acc: 0.8330 - val_loss: 0.3989 - val_acc: 0.8227\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 13s 748us/step - loss: 0.3363 - acc: 0.8509 - val_loss: 0.3858 - val_acc: 0.8270\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 13s 752us/step - loss: 0.3077 - acc: 0.8652 - val_loss: 0.3983 - val_acc: 0.8200\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 13s 754us/step - loss: 0.2724 - acc: 0.8845 - val_loss: 0.3781 - val_acc: 0.8374\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 13s 734us/step - loss: 0.2401 - acc: 0.9001 - val_loss: 0.3959 - val_acc: 0.8363\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 15s 885us/step - loss: 0.2082 - acc: 0.9139 - val_loss: 0.3860 - val_acc: 0.8457\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 7s 428us/step - loss: 0.6127 - acc: 0.6666 - val_loss: 0.5548 - val_acc: 0.7214\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 7s 414us/step - loss: 0.5131 - acc: 0.7480 - val_loss: 0.5386 - val_acc: 0.7292\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 7s 420us/step - loss: 0.4663 - acc: 0.7800 - val_loss: 0.5355 - val_acc: 0.7318\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 7s 417us/step - loss: 0.4183 - acc: 0.8079 - val_loss: 0.5535 - val_acc: 0.7302\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 7s 395us/step - loss: 0.3688 - acc: 0.8351 - val_loss: 0.5619 - val_acc: 0.7300\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 7s 394us/step - loss: 0.3147 - acc: 0.8661 - val_loss: 0.6207 - val_acc: 0.7296\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 7s 400us/step - loss: 0.2613 - acc: 0.8886 - val_loss: 0.6631 - val_acc: 0.7286\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 7s 396us/step - loss: 0.2060 - acc: 0.9179 - val_loss: 0.7156 - val_acc: 0.7314\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 7s 418us/step - loss: 0.1589 - acc: 0.9408 - val_loss: 0.7296 - val_acc: 0.7221\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 12s 705us/step - loss: 0.1100 - acc: 0.9651 - val_loss: 0.8229 - val_acc: 0.7272\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 8s 432us/step - loss: 0.6073 - acc: 0.6640 - val_loss: 0.5527 - val_acc: 0.7215\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 7s 415us/step - loss: 0.5113 - acc: 0.7483 - val_loss: 0.5048 - val_acc: 0.7575\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 7s 414us/step - loss: 0.4667 - acc: 0.7785 - val_loss: 0.4942 - val_acc: 0.7599\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 7s 420us/step - loss: 0.4310 - acc: 0.8007 - val_loss: 0.4842 - val_acc: 0.7675\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 7s 415us/step - loss: 0.3939 - acc: 0.8229 - val_loss: 0.4717 - val_acc: 0.7773\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 7s 416us/step - loss: 0.3514 - acc: 0.8453 - val_loss: 0.4558 - val_acc: 0.7910\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 7s 414us/step - loss: 0.3127 - acc: 0.8639 - val_loss: 0.5191 - val_acc: 0.7634\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 7s 419us/step - loss: 0.2691 - acc: 0.8888 - val_loss: 0.5120 - val_acc: 0.7875\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 7s 417us/step - loss: 0.2304 - acc: 0.9072 - val_loss: 0.5316 - val_acc: 0.7829\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 7s 414us/step - loss: 0.1855 - acc: 0.9268 - val_loss: 0.6038 - val_acc: 0.7755\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 8s 451us/step - loss: 0.6324 - acc: 0.6316 - val_loss: 0.5765 - val_acc: 0.6962\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 8s 438us/step - loss: 0.5385 - acc: 0.7282 - val_loss: 0.5317 - val_acc: 0.7274\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 8s 432us/step - loss: 0.4894 - acc: 0.7617 - val_loss: 0.5177 - val_acc: 0.7469\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 8s 432us/step - loss: 0.4489 - acc: 0.7847 - val_loss: 0.4596 - val_acc: 0.7809\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17462/17462 [==============================] - 8s 433us/step - loss: 0.4192 - acc: 0.8061 - val_loss: 0.4780 - val_acc: 0.7743\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 8s 437us/step - loss: 0.3887 - acc: 0.8233 - val_loss: 0.4394 - val_acc: 0.7953\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 7s 429us/step - loss: 0.3607 - acc: 0.8360 - val_loss: 0.4120 - val_acc: 0.8156\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 7s 427us/step - loss: 0.3347 - acc: 0.8512 - val_loss: 0.4051 - val_acc: 0.8176\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 7s 429us/step - loss: 0.3106 - acc: 0.8629 - val_loss: 0.3990 - val_acc: 0.8268\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 8s 436us/step - loss: 0.2868 - acc: 0.8740 - val_loss: 0.4044 - val_acc: 0.8244\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 10s 561us/step - loss: 0.6077 - acc: 0.6717 - val_loss: 0.5616 - val_acc: 0.7121\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 9s 542us/step - loss: 0.4995 - acc: 0.7591 - val_loss: 0.5477 - val_acc: 0.7294\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 10s 546us/step - loss: 0.4324 - acc: 0.8033 - val_loss: 0.5345 - val_acc: 0.7364\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 10s 547us/step - loss: 0.3672 - acc: 0.8330 - val_loss: 0.5469 - val_acc: 0.7406\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 9s 542us/step - loss: 0.2930 - acc: 0.8754 - val_loss: 0.6258 - val_acc: 0.7401\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 10s 552us/step - loss: 0.2066 - acc: 0.9183 - val_loss: 0.6712 - val_acc: 0.7334\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 9s 542us/step - loss: 0.1409 - acc: 0.9489 - val_loss: 0.7509 - val_acc: 0.7414\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 9s 540us/step - loss: 0.0864 - acc: 0.9722 - val_loss: 0.8963 - val_acc: 0.7377\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 9s 543us/step - loss: 0.0521 - acc: 0.9860 - val_loss: 1.0037 - val_acc: 0.7362\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 10s 547us/step - loss: 0.0367 - acc: 0.9917 - val_loss: 1.1143 - val_acc: 0.7316\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 9s 543us/step - loss: 0.6435 - acc: 0.6202 - val_loss: 0.5775 - val_acc: 0.6932\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 9s 539us/step - loss: 0.5361 - acc: 0.7300 - val_loss: 0.5306 - val_acc: 0.7333\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 9s 525us/step - loss: 0.4680 - acc: 0.7759 - val_loss: 0.5106 - val_acc: 0.7485\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 9s 519us/step - loss: 0.4158 - acc: 0.8089 - val_loss: 0.4795 - val_acc: 0.7672\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 9s 517us/step - loss: 0.3623 - acc: 0.8394 - val_loss: 0.4971 - val_acc: 0.7674\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 9s 529us/step - loss: 0.3072 - acc: 0.8685 - val_loss: 0.4880 - val_acc: 0.7841\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 9s 518us/step - loss: 0.2421 - acc: 0.9005 - val_loss: 0.5488 - val_acc: 0.7803\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 9s 518us/step - loss: 0.1828 - acc: 0.9290 - val_loss: 0.6063 - val_acc: 0.7807\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 10s 544us/step - loss: 0.1212 - acc: 0.9543 - val_loss: 0.7294 - val_acc: 0.7751\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 9s 529us/step - loss: 0.0768 - acc: 0.9750 - val_loss: 0.8718 - val_acc: 0.7738\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 10s 554us/step - loss: 0.6548 - acc: 0.5959 - val_loss: 0.6012 - val_acc: 0.6789\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 10s 552us/step - loss: 0.5254 - acc: 0.7383 - val_loss: 0.4832 - val_acc: 0.7696\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 9s 521us/step - loss: 0.4541 - acc: 0.7844 - val_loss: 0.4422 - val_acc: 0.7944\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 9s 533us/step - loss: 0.4066 - acc: 0.8140 - val_loss: 0.4168 - val_acc: 0.8125\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 10s 551us/step - loss: 0.3660 - acc: 0.8349 - val_loss: 0.4069 - val_acc: 0.8215\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 10s 547us/step - loss: 0.3260 - acc: 0.8543 - val_loss: 0.4047 - val_acc: 0.8175\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 9s 535us/step - loss: 0.2827 - acc: 0.8795 - val_loss: 0.3970 - val_acc: 0.8308\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 10s 561us/step - loss: 0.2465 - acc: 0.8973 - val_loss: 0.3987 - val_acc: 0.8306\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 9s 534us/step - loss: 0.2136 - acc: 0.9095 - val_loss: 0.4247 - val_acc: 0.8319\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 9s 534us/step - loss: 0.1725 - acc: 0.9298 - val_loss: 0.4583 - val_acc: 0.8286\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 20s 1ms/step - loss: 0.6343 - acc: 0.6581 - val_loss: 0.5757 - val_acc: 0.7103\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 18s 1ms/step - loss: 0.5169 - acc: 0.7448 - val_loss: 0.5733 - val_acc: 0.6980\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 18s 1ms/step - loss: 0.4512 - acc: 0.7863 - val_loss: 0.5475 - val_acc: 0.7361\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 18s 1ms/step - loss: 0.3691 - acc: 0.8327 - val_loss: 0.5639 - val_acc: 0.7376\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 21s 1ms/step - loss: 0.2590 - acc: 0.8917 - val_loss: 0.6370 - val_acc: 0.7324\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 18s 1ms/step - loss: 0.1658 - acc: 0.9344 - val_loss: 0.7305 - val_acc: 0.7360\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 18s 1ms/step - loss: 0.0850 - acc: 0.9719 - val_loss: 0.8576 - val_acc: 0.7365\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 18s 1ms/step - loss: 0.0452 - acc: 0.9883 - val_loss: 1.0931 - val_acc: 0.7263\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 18s 1ms/step - loss: 0.0248 - acc: 0.9954 - val_loss: 1.3817 - val_acc: 0.7255\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 18s 1ms/step - loss: 0.0261 - acc: 0.9940 - val_loss: 1.2779 - val_acc: 0.7285\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 15s 833us/step - loss: 0.6379 - acc: 0.6306 - val_loss: 0.5759 - val_acc: 0.6976\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 14s 805us/step - loss: 0.5283 - acc: 0.7408 - val_loss: 0.5081 - val_acc: 0.7541\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 14s 812us/step - loss: 0.4605 - acc: 0.7791 - val_loss: 0.4874 - val_acc: 0.7630\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 14s 807us/step - loss: 0.4010 - acc: 0.8142 - val_loss: 0.5144 - val_acc: 0.7509\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 14s 816us/step - loss: 0.3367 - acc: 0.8504 - val_loss: 0.5141 - val_acc: 0.7749\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 14s 810us/step - loss: 0.2447 - acc: 0.8997 - val_loss: 0.5504 - val_acc: 0.7670\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 14s 813us/step - loss: 0.1577 - acc: 0.9386 - val_loss: 0.6619 - val_acc: 0.7643\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 14s 807us/step - loss: 0.0875 - acc: 0.9700 - val_loss: 0.8301 - val_acc: 0.7576\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 14s 827us/step - loss: 0.0463 - acc: 0.9862 - val_loss: 1.0516 - val_acc: 0.7590\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 14s 809us/step - loss: 0.0314 - acc: 0.9907 - val_loss: 1.1027 - val_acc: 0.7670\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 14s 804us/step - loss: 0.6366 - acc: 0.6235 - val_loss: 0.5872 - val_acc: 0.6900\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17462/17462 [==============================] - 14s 773us/step - loss: 0.5075 - acc: 0.7499 - val_loss: 0.4696 - val_acc: 0.7817\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 14s 781us/step - loss: 0.4330 - acc: 0.7966 - val_loss: 0.4272 - val_acc: 0.8037\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 14s 774us/step - loss: 0.3801 - acc: 0.8273 - val_loss: 0.3894 - val_acc: 0.8287\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 14s 781us/step - loss: 0.3332 - acc: 0.8507 - val_loss: 0.3810 - val_acc: 0.8272\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 14s 774us/step - loss: 0.2835 - acc: 0.8790 - val_loss: 0.3903 - val_acc: 0.8247\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 13s 772us/step - loss: 0.2403 - acc: 0.8970 - val_loss: 0.4046 - val_acc: 0.8300\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 14s 779us/step - loss: 0.1912 - acc: 0.9217 - val_loss: 0.4385 - val_acc: 0.8343\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 14s 789us/step - loss: 0.1440 - acc: 0.9428 - val_loss: 0.4537 - val_acc: 0.8406\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 14s 798us/step - loss: 0.0994 - acc: 0.9620 - val_loss: 0.5429 - val_acc: 0.8370\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 8s 467us/step - loss: 0.6244 - acc: 0.6474 - val_loss: 0.6173 - val_acc: 0.6577\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 8s 433us/step - loss: 0.5279 - acc: 0.7427 - val_loss: 0.5545 - val_acc: 0.7206\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 8s 446us/step - loss: 0.4679 - acc: 0.7791 - val_loss: 0.5429 - val_acc: 0.7345\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 8s 433us/step - loss: 0.4198 - acc: 0.8078 - val_loss: 0.5656 - val_acc: 0.7290\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 8s 432us/step - loss: 0.3668 - acc: 0.8357 - val_loss: 0.5818 - val_acc: 0.7250\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 8s 431us/step - loss: 0.3125 - acc: 0.8647 - val_loss: 0.6751 - val_acc: 0.7083\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 8s 445us/step - loss: 0.2519 - acc: 0.8943 - val_loss: 0.7166 - val_acc: 0.7126\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 8s 431us/step - loss: 0.1931 - acc: 0.9222 - val_loss: 0.8099 - val_acc: 0.7019\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 8s 432us/step - loss: 0.1414 - acc: 0.9469 - val_loss: 0.9644 - val_acc: 0.7074\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 8s 431us/step - loss: 0.1016 - acc: 0.9625 - val_loss: 1.1580 - val_acc: 0.7131\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 8s 472us/step - loss: 0.6552 - acc: 0.5982 - val_loss: 0.6011 - val_acc: 0.6757\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 8s 449us/step - loss: 0.5433 - acc: 0.7268 - val_loss: 0.5239 - val_acc: 0.7445\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 8s 455us/step - loss: 0.4779 - acc: 0.7739 - val_loss: 0.4860 - val_acc: 0.7648\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 8s 458us/step - loss: 0.4431 - acc: 0.7922 - val_loss: 0.4944 - val_acc: 0.7595\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 8s 451us/step - loss: 0.4123 - acc: 0.8096 - val_loss: 0.4704 - val_acc: 0.7809\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 8s 447us/step - loss: 0.3759 - acc: 0.8295 - val_loss: 0.4911 - val_acc: 0.7774\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 8s 445us/step - loss: 0.3459 - acc: 0.8475 - val_loss: 0.4903 - val_acc: 0.7683\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 8s 460us/step - loss: 0.3187 - acc: 0.8604 - val_loss: 0.4954 - val_acc: 0.7758\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 8s 455us/step - loss: 0.2851 - acc: 0.8776 - val_loss: 0.5109 - val_acc: 0.7799\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 8s 452us/step - loss: 0.2507 - acc: 0.8944 - val_loss: 0.5700 - val_acc: 0.7843\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 9s 524us/step - loss: 0.6657 - acc: 0.5877 - val_loss: 0.6190 - val_acc: 0.6694\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 8s 473us/step - loss: 0.5483 - acc: 0.7231 - val_loss: 0.5238 - val_acc: 0.7441\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 8s 465us/step - loss: 0.4829 - acc: 0.7695 - val_loss: 0.4667 - val_acc: 0.7826\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 8s 465us/step - loss: 0.4421 - acc: 0.7908 - val_loss: 0.4600 - val_acc: 0.7849\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 8s 481us/step - loss: 0.4070 - acc: 0.8149 - val_loss: 0.4180 - val_acc: 0.8080\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 8s 467us/step - loss: 0.3848 - acc: 0.8243 - val_loss: 0.4255 - val_acc: 0.8053\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 8s 467us/step - loss: 0.3529 - acc: 0.8416 - val_loss: 0.4042 - val_acc: 0.8171\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 8s 465us/step - loss: 0.3264 - acc: 0.8573 - val_loss: 0.3914 - val_acc: 0.8231\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 9s 492us/step - loss: 0.3020 - acc: 0.8707 - val_loss: 0.4365 - val_acc: 0.7986\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 8s 467us/step - loss: 0.2801 - acc: 0.8799 - val_loss: 0.4040 - val_acc: 0.8251\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 11s 634us/step - loss: 0.6101 - acc: 0.6631 - val_loss: 0.5817 - val_acc: 0.6958\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 10s 593us/step - loss: 0.5127 - acc: 0.7492 - val_loss: 0.5453 - val_acc: 0.7288\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 10s 600us/step - loss: 0.4547 - acc: 0.7829 - val_loss: 0.5536 - val_acc: 0.7289\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 11s 613us/step - loss: 0.3976 - acc: 0.8201 - val_loss: 0.5709 - val_acc: 0.7146\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 10s 600us/step - loss: 0.3327 - acc: 0.8494 - val_loss: 0.6376 - val_acc: 0.7302\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 10s 588us/step - loss: 0.2616 - acc: 0.8845 - val_loss: 0.7491 - val_acc: 0.7225\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 10s 597us/step - loss: 0.2027 - acc: 0.9150 - val_loss: 0.8409 - val_acc: 0.7115\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 11s 611us/step - loss: 0.1398 - acc: 0.9435 - val_loss: 1.0058 - val_acc: 0.7147\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 11s 604us/step - loss: 0.1018 - acc: 0.9607 - val_loss: 1.2076 - val_acc: 0.7193\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 10s 583us/step - loss: 0.0814 - acc: 0.9706 - val_loss: 1.3505 - val_acc: 0.7078\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 10s 591us/step - loss: 0.6339 - acc: 0.6326 - val_loss: 0.6192 - val_acc: 0.6534\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 11s 603us/step - loss: 0.5448 - acc: 0.7263 - val_loss: 0.5364 - val_acc: 0.7254\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 10s 600us/step - loss: 0.4738 - acc: 0.7723 - val_loss: 0.4952 - val_acc: 0.7638\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 10s 564us/step - loss: 0.4184 - acc: 0.8062 - val_loss: 0.5179 - val_acc: 0.7533\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 10s 588us/step - loss: 0.3534 - acc: 0.8392 - val_loss: 0.5021 - val_acc: 0.7690\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 10s 580us/step - loss: 0.2782 - acc: 0.8787 - val_loss: 0.6000 - val_acc: 0.7648\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 10s 553us/step - loss: 0.1978 - acc: 0.9168 - val_loss: 0.6808 - val_acc: 0.7674\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 10s 563us/step - loss: 0.1227 - acc: 0.9529 - val_loss: 0.8484 - val_acc: 0.7616\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17462/17462 [==============================] - 10s 549us/step - loss: 0.0769 - acc: 0.9717 - val_loss: 1.0606 - val_acc: 0.7555\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 10s 549us/step - loss: 0.0556 - acc: 0.9806 - val_loss: 1.1715 - val_acc: 0.7541\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 12s 675us/step - loss: 0.6452 - acc: 0.6179 - val_loss: 0.5918 - val_acc: 0.6889\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 10s 574us/step - loss: 0.5214 - acc: 0.7425 - val_loss: 0.4873 - val_acc: 0.7667\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 10s 565us/step - loss: 0.4370 - acc: 0.8000 - val_loss: 0.4352 - val_acc: 0.7978\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 11s 640us/step - loss: 0.3853 - acc: 0.8273 - val_loss: 0.3955 - val_acc: 0.8187\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 10s 564us/step - loss: 0.3472 - acc: 0.8457 - val_loss: 0.4212 - val_acc: 0.8013\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 10s 562us/step - loss: 0.3100 - acc: 0.8640 - val_loss: 0.3964 - val_acc: 0.8211\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 10s 560us/step - loss: 0.2785 - acc: 0.8788 - val_loss: 0.4234 - val_acc: 0.8137\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 10s 568us/step - loss: 0.2377 - acc: 0.8990 - val_loss: 0.4214 - val_acc: 0.8260\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 10s 571us/step - loss: 0.2060 - acc: 0.9142 - val_loss: 0.4491 - val_acc: 0.8184\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 10s 564us/step - loss: 0.1738 - acc: 0.9286 - val_loss: 0.5895 - val_acc: 0.8132\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 19s 1ms/step - loss: 0.6256 - acc: 0.6623 - val_loss: 0.5647 - val_acc: 0.7129\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 18s 1ms/step - loss: 0.5004 - acc: 0.7580 - val_loss: 0.5580 - val_acc: 0.7159\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 18s 1ms/step - loss: 0.4139 - acc: 0.8102 - val_loss: 0.5956 - val_acc: 0.7064\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 18s 1ms/step - loss: 0.3010 - acc: 0.8715 - val_loss: 0.6263 - val_acc: 0.7266\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 18s 1ms/step - loss: 0.1818 - acc: 0.9244 - val_loss: 0.8403 - val_acc: 0.7046\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 18s 1ms/step - loss: 0.0932 - acc: 0.9660 - val_loss: 1.1285 - val_acc: 0.7202\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 18s 1ms/step - loss: 0.0636 - acc: 0.9781 - val_loss: 1.3304 - val_acc: 0.7145\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 18s 1ms/step - loss: 0.0446 - acc: 0.9859 - val_loss: 1.5231 - val_acc: 0.7102\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 18s 1ms/step - loss: 0.0374 - acc: 0.9881 - val_loss: 1.4722 - val_acc: 0.7095\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 18s 1ms/step - loss: 0.0324 - acc: 0.9896 - val_loss: 1.5481 - val_acc: 0.7111\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 15s 845us/step - loss: 0.6426 - acc: 0.6254 - val_loss: 0.6021 - val_acc: 0.6753\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 15s 831us/step - loss: 0.5487 - acc: 0.7213 - val_loss: 0.5269 - val_acc: 0.7406\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 14s 820us/step - loss: 0.4769 - acc: 0.7731 - val_loss: 0.4911 - val_acc: 0.7606\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 15s 842us/step - loss: 0.4259 - acc: 0.8019 - val_loss: 0.4862 - val_acc: 0.7663\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 14s 819us/step - loss: 0.3688 - acc: 0.8334 - val_loss: 0.4925 - val_acc: 0.7734\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 14s 830us/step - loss: 0.2960 - acc: 0.8724 - val_loss: 0.5656 - val_acc: 0.7586\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 14s 821us/step - loss: 0.2140 - acc: 0.9135 - val_loss: 0.6284 - val_acc: 0.7642\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 15s 854us/step - loss: 0.1364 - acc: 0.9476 - val_loss: 0.7954 - val_acc: 0.7573\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 15s 842us/step - loss: 0.0888 - acc: 0.9674 - val_loss: 1.0307 - val_acc: 0.7568\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 15s 839us/step - loss: 0.0595 - acc: 0.9776 - val_loss: 1.0605 - val_acc: 0.7650\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 14s 824us/step - loss: 0.6601 - acc: 0.5881 - val_loss: 0.5847 - val_acc: 0.6937\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 14s 822us/step - loss: 0.5420 - acc: 0.7297 - val_loss: 0.5011 - val_acc: 0.7543\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 14s 794us/step - loss: 0.4601 - acc: 0.7827 - val_loss: 0.4892 - val_acc: 0.7598\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 14s 801us/step - loss: 0.4003 - acc: 0.8156 - val_loss: 0.4211 - val_acc: 0.8093\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 14s 803us/step - loss: 0.3538 - acc: 0.8426 - val_loss: 0.4587 - val_acc: 0.7930\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 14s 804us/step - loss: 0.2937 - acc: 0.8730 - val_loss: 0.4318 - val_acc: 0.8104\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 14s 808us/step - loss: 0.2232 - acc: 0.9090 - val_loss: 0.4996 - val_acc: 0.7985\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 16s 906us/step - loss: 0.1591 - acc: 0.9368 - val_loss: 0.6084 - val_acc: 0.8071\n",
      "Epoch 9/10\n",
      "   32/17462 [..............................] - ETA: 1:06 - loss: 0.1377 - acc: 0.9688WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.103160). Check your callbacks.\n",
      "17462/17462 [==============================] - 14s 816us/step - loss: 0.1094 - acc: 0.9582 - val_loss: 0.6951 - val_acc: 0.7954\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 22s 1ms/step - loss: 0.0760 - acc: 0.9702 - val_loss: 0.7050 - val_acc: 0.8002\n"
     ]
    }
   ],
   "source": [
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "            \n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            for l in range(conv_layer - 1):\n",
    "                model.add(Conv2D(layer_size, (3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "            for l in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "            \n",
    "            model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "            \n",
    "            model.fit(X, y, batch_size=32, epochs=10, validation_split=0.3, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
